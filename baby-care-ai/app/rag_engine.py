"""
Baby Care AI - RAG Engine with ChromaDB Fallback
Retrieval-Augmented Generation engine for baby care knowledge base
"""

import os
import yaml
from typing import List, Dict, Any
from pathlib import Path

# Disable ChromaDB telemetry to avoid posthog errors
os.environ["ANONYMIZED_TELEMETRY"] = "False"

import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Try to import ChromaDB dependencies, fall back if they fail
try:
    import chromadb
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain_community.document_loaders import DirectoryLoader, TextLoader
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain_core.documents import Document
    from langchain_core.retrievers import BaseRetriever
    CHROMADB_AVAILABLE = True
    logger.info("âœ… ChromaDB dependencies loaded successfully")
except Exception as e:
    CHROMADB_AVAILABLE = False
    logger.warning(f"âš ï¸ ChromaDB dependencies failed to load: {e}")
    logger.info("ğŸ”„ Will use fallback TF-IDF implementation")
    # Create a mock BaseRetriever for fallback
    class BaseRetriever:
        pass
    # Create mock Document class
    class Document:
        def __init__(self, page_content="", metadata=None):
            self.page_content = page_content
            self.metadata = metadata or {}

# Fallback engine removed - ChromaDB is now working properly

# FallbackRetriever removed - ChromaDB is now working properly

class ChromaDBWrapper:
    """Custom ChromaDB wrapper to bypass LangChain deprecated configuration"""
    
    def __init__(self, client, collection, embedding_function):
        self.client = client
        self.collection = collection
        self.embedding_function = embedding_function
    
    def add_documents(self, documents):
        """Add documents to the collection"""
        if not documents:
            logger.warning("No documents to add")
            return
            
        texts = [doc.page_content for doc in documents]
        metadatas = [doc.metadata for doc in documents]
        
        # Generate unique IDs to avoid conflicts
        import time
        timestamp = int(time.time() * 1000)
        ids = [f"doc_{timestamp}_{i}" for i in range(len(documents))]
        
        try:
            # Generate embeddings
            embeddings = self.embedding_function.embed_documents(texts)
            
            # Add to collection in batches to avoid memory issues
            batch_size = 100
            for i in range(0, len(documents), batch_size):
                batch_end = min(i + batch_size, len(documents))
                batch_embeddings = embeddings[i:batch_end]
                batch_texts = texts[i:batch_end]
                batch_metadatas = metadatas[i:batch_end]
                batch_ids = ids[i:batch_end]
                
                self.collection.add(
                    embeddings=batch_embeddings,
                    documents=batch_texts,
                    metadatas=batch_metadatas,
                    ids=batch_ids
                )
                logger.info(f"Added batch {i//batch_size + 1}: {len(batch_texts)} documents")
                
        except Exception as e:
            logger.error(f"Failed to add documents: {e}")
            raise
    
    def similarity_search(self, query, k=4):
        """Search for similar documents"""
        try:
            # Generate query embedding
            query_embedding = self.embedding_function.embed_query(query)
            
            # Query the collection
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=min(k, 10)  # Limit to reasonable number
            )
            
            # Convert results to Document objects
            documents = []
            if results and 'documents' in results and results['documents'] and results['documents'][0]:
                for i, doc_text in enumerate(results['documents'][0]):
                    metadata = {}
                    if results.get('metadatas') and results['metadatas'][0] and i < len(results['metadatas'][0]):
                        metadata = results['metadatas'][0][i] or {}
                    
                    if CHROMADB_AVAILABLE:
                        doc = Document(page_content=doc_text, metadata=metadata)
                    else:
                        doc = type('Document', (), {
                            'page_content': doc_text,
                            'metadata': metadata
                        })()
                    documents.append(doc)
            
            logger.info(f"Found {len(documents)} similar documents for query")
            return documents
            
        except Exception as e:
            logger.error(f"Similarity search failed: {e}")
            return []
    
    def as_retriever(self, search_type="similarity", search_kwargs=None):
        """Return a retriever interface"""
        if search_kwargs is None:
            search_kwargs = {"k": 4}
        return ChromaDBRetriever(self, search_kwargs.get("k", 4))

class ChromaDBRetriever:
    """Custom retriever for ChromaDB wrapper"""
    
    def __init__(self, vectorstore, k=4):
        self.vectorstore = vectorstore
        self.k = k
        self.search_type = "similarity"
        self.search_kwargs = {"k": k}
    
    def get_relevant_documents(self, query):
        """Get relevant documents for a query"""
        return self.vectorstore.similarity_search(query, k=self.k)
    
    def invoke(self, query):
        """Invoke method for compatibility"""
        return self.get_relevant_documents(query)

class RAGEngine:
    """RAG Engine for Baby Care AI knowledge base with automatic fallback"""
    
    def __init__(self, config_path: str = None):
        """åˆå§‹åŒ–RAGå¼•æ“"""
        if config_path is None:
            # Get the project root directory (parent of app directory)
            project_root = Path(__file__).parent.parent
            config_path = project_root / "config" / "ollama_config.yaml"
        self.config = self._load_config(str(config_path))
        self.embeddings = None
        self.vectorstore = None
        self.retriever = None
        self._setup_embeddings()
        
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        with open(config_path, 'r', encoding='utf-8') as file:
            return yaml.safe_load(file)
    
    def _setup_embeddings(self):
        """è®¾ç½®åµŒå…¥æ¨¡å‹"""
        if not CHROMADB_AVAILABLE:
            logger.info("ğŸ”„ ChromaDB not available, skipping embeddings setup")
            return
            
        try:
            model_name = self.config['embedding']['model']
            self.embeddings = HuggingFaceEmbeddings(
                model_name=model_name,
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )
            logger.info("âœ… Embeddings model initialized successfully")
        except Exception as e:
            logger.error(f"âŒ Failed to setup embeddings: {e}")
            logger.info("ğŸ”„ Will use fallback implementation")
    
    def _initialize_chromadb(self):
        """Initialize ChromaDB-based RAG engine"""
        try:
            # Initialize vector store
            persist_directory = self.config['vector_db']['persist_directory']
            collection_name = self.config['vector_db']['collection_name']
            
            # Ensure directory exists
            os.makedirs(persist_directory, exist_ok=True)
            
            # Create ChromaDB persistent client to save to disk
            try:
                # Use PersistentClient to save data to disk
                self.chroma_client = chromadb.PersistentClient(path=persist_directory)
                logger.info(f"âœ… ChromaDB PersistentClient created successfully at {persist_directory}")
                
                # Get or create collection with error handling
                try:
                    self.collection = self.chroma_client.get_collection(name=collection_name)
                    logger.info(f"âœ… Retrieved existing collection: {collection_name}")
                except Exception as get_error:
                    logger.info(f"Collection doesn't exist, creating new one: {get_error}")
                    try:
                        self.collection = self.chroma_client.create_collection(
                            name=collection_name,
                            metadata={"hnsw:space": "cosine"}  # Use cosine similarity
                        )
                        logger.info(f"âœ… Created new collection: {collection_name}")
                    except Exception as create_error:
                        logger.warning(f"Failed to create collection with metadata, trying simple creation: {create_error}")
                        self.collection = self.chroma_client.create_collection(name=collection_name)
                        logger.info(f"âœ… Created new collection (simple): {collection_name}")
                
                # Create a custom vectorstore wrapper
                self.vectorstore = ChromaDBWrapper(
                    client=self.chroma_client,
                    collection=self.collection,
                    embedding_function=self.embeddings
                )
                
                logger.info("âœ… ChromaDB RAG Engine initialized successfully")
                
            except Exception as e:
                logger.error(f"âŒ ChromaDB PersistentClient initialization failed: {e}")
                # Fallback to in-memory client if persistent fails
                logger.info("ğŸ”„ Falling back to in-memory ChromaDB client")
                try:
                    self.chroma_client = chromadb.Client()
                    logger.info("âœ… ChromaDB in-memory Client created successfully")
                    
                    # Get or create collection
                    try:
                        self.collection = self.chroma_client.get_collection(name=collection_name)
                        logger.info(f"âœ… Retrieved existing collection: {collection_name}")
                    except:
                        self.collection = self.chroma_client.create_collection(name=collection_name)
                        logger.info(f"âœ… Created new collection: {collection_name}")
                    
                    # Create a custom vectorstore wrapper
                    self.vectorstore = ChromaDBWrapper(
                        client=self.chroma_client,
                        collection=self.collection,
                        embedding_function=self.embeddings
                    )
                    
                    logger.info("âœ… ChromaDB RAG Engine initialized successfully (in-memory)")
                except Exception as fallback_error:
                    logger.error(f"âŒ Even in-memory ChromaDB failed: {fallback_error}")
                    raise
            
        except Exception as e:
            logger.error(f"âŒ ChromaDB initialization failed: {e}")
            raise
    
    def _initialize_fallback(self):
        """Fallback initialization removed - ChromaDB is now working properly"""
        logger.error("âŒ ChromaDB initialization failed and fallback has been removed")
        raise RuntimeError("ChromaDB initialization failed and no fallback available")
    
    def load_documents(self, data_dirs: List[str]) -> List:
        """åŠ è½½æ–‡æ¡£"""
        if not CHROMADB_AVAILABLE:
            logger.error("âŒ load_documents called without ChromaDB dependencies")
            return []
            
        documents = []
        
        for data_dir in data_dirs:
            if not os.path.exists(data_dir):
                print(f"è­¦å‘Š: ç›®å½• {data_dir} ä¸å­˜åœ¨")
                continue
                
            # åŠ è½½markdownæ–‡ä»¶
            if any(Path(data_dir).glob("*.md")):
                md_loader = DirectoryLoader(
                    data_dir,
                    glob="*.md",
                    loader_cls=TextLoader,
                    loader_kwargs={'encoding': 'utf-8'}
                )
                documents.extend(md_loader.load())
            
            # åŠ è½½txtæ–‡ä»¶
            if any(Path(data_dir).glob("*.txt")):
                txt_loader = DirectoryLoader(
                    data_dir,
                    glob="*.txt",
                    loader_cls=TextLoader,
                    loader_kwargs={'encoding': 'utf-8'}
                )
                documents.extend(txt_loader.load())
        
        print(f"æˆåŠŸåŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£")
        return documents
    
    def split_documents(self, documents: List) -> List:
        """åˆ†å‰²æ–‡æ¡£"""
        if not CHROMADB_AVAILABLE:
            logger.error("âŒ split_documents called without ChromaDB dependencies")
            return []
            
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.config['embedding']['chunk_size'],
            chunk_overlap=self.config['embedding']['chunk_overlap'],
            separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", " ", ""]
        )
        
        split_docs = text_splitter.split_documents(documents)
        print(f"æ–‡æ¡£åˆ†å‰²å®Œæˆï¼Œå…± {len(split_docs)} ä¸ªç‰‡æ®µ")
        return split_docs
    
    def create_vectorstore(self, documents: List):
        """åˆ›å»ºå‘é‡æ•°æ®åº“"""
        # Add documents to the existing vectorstore
        if hasattr(self, 'vectorstore') and self.vectorstore:
            self.vectorstore.add_documents(documents)
            print(f"å‘é‡æ•°æ®åº“åˆ›å»ºå®Œæˆï¼Œæ·»åŠ äº† {len(documents)} ä¸ªæ–‡æ¡£")
        else:
            logger.error("âŒ Vectorstore not initialized")
    
    def load_vectorstore(self):
        """åŠ è½½å·²å­˜åœ¨çš„å‘é‡æ•°æ®åº“"""
        # The vectorstore is already initialized in _initialize_chromadb
        if hasattr(self, 'vectorstore') and self.vectorstore:
            print("å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸ")
        else:
            print("å‘é‡æ•°æ®åº“ä¸å­˜åœ¨ï¼Œéœ€è¦å…ˆåˆ›å»º")
    
    def setup_retriever(self, k: int = 4):
        """è®¾ç½®æ£€ç´¢å™¨"""
        if self.vectorstore is None:
            raise ValueError("å‘é‡æ•°æ®åº“æœªåˆå§‹åŒ–")
        
        self.retriever = self.vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": k}
        )
        print(f"æ£€ç´¢å™¨è®¾ç½®å®Œæˆï¼Œè¿”å›top-{k}ç›¸å…³æ–‡æ¡£")
    
    def retrieve_documents(self, query: str) -> List:
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        if self.retriever is None:
            raise ValueError("æ£€ç´¢å™¨æœªåˆå§‹åŒ–")
        
        relevant_docs = self.retriever.invoke(query)
        return relevant_docs
    
    def initialize_rag(self, data_dirs: List[str], force_rebuild: bool = False):
        """åˆå§‹åŒ–RAGç³»ç»Ÿ"""
        if not CHROMADB_AVAILABLE:
            logger.error("âŒ ChromaDB dependencies not available")
            return False
            
        try:
            self._initialize_chromadb()
            
            persist_directory = self.config['vector_db']['persist_directory']
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å»ºå‘é‡æ•°æ®åº“
            if force_rebuild or not os.path.exists(persist_directory):
                print("å¼€å§‹æ„å»ºå‘é‡æ•°æ®åº“...")
                documents = self.load_documents(data_dirs)
                if documents:
                    split_docs = self.split_documents(documents)
                    self.create_vectorstore(split_docs)
                else:
                    print("æ²¡æœ‰æ‰¾åˆ°æ–‡æ¡£ï¼Œæ— æ³•æ„å»ºå‘é‡æ•°æ®åº“")
                    return False
            else:
                print("åŠ è½½ç°æœ‰å‘é‡æ•°æ®åº“...")
                self.load_vectorstore()
            
            # è®¾ç½®æ£€ç´¢å™¨
            self.setup_retriever()
            return True
            
        except Exception as e:
            logger.error(f"âŒ ChromaDB initialization failed: {e}")
            return False

if __name__ == "__main__":
    # æµ‹è¯•RAGå¼•æ“
    rag_engine = RAGEngine()
    data_dirs = ["data/knowledge", "data/faq"]
    
    if rag_engine.initialize_rag(data_dirs, force_rebuild=True):
        # æµ‹è¯•æ£€ç´¢
        query = "æ–°ç”Ÿå„¿å–‚å…»"
        docs = rag_engine.retrieve_documents(query)
        print(f"\næ£€ç´¢ç»“æœ (æŸ¥è¯¢: {query}):")
        for i, doc in enumerate(docs):
            if hasattr(doc, 'page_content'):
                print(f"æ–‡æ¡£ {i+1}: {doc.page_content[:100]}...")
            else:
                print(f"æ–‡æ¡£ {i+1}: {doc.get('content', '')[:100]}...")