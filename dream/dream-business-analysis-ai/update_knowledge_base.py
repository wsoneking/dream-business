#!/usr/bin/env python3
"""
DREAM Business Analysis AI - Knowledge Base Update Script
Update frameworks, templates, case studies, and benchmarks from class notes using LLM analysis
"""

import asyncio
import sys
import shutil
import json
import re
import yaml
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any

# Add the project root to Python path
sys.path.append(str(Path(__file__).parent))

from langchain_ollama import OllamaLLM
from langchain_core.prompts import PromptTemplate

class LLMContentGenerator:
    """Generate knowledge base content using LLM analysis of class notes"""
    
    def __init__(self, class_notes_path: Path, config_path: Path):
        self.class_notes_path = class_notes_path
        self.config_path = config_path
        self.llm = None
        self.processed_content = {}
        self._initialize_llm()
    
    def _initialize_llm(self):
        """Initialize the Ollama LLM"""
        try:
            # Load configuration
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            self.llm = OllamaLLM(
                base_url=config["ollama"]["base_url"],
                model=config["ollama"]["model"],
                temperature=config["ollama"]["temperature"],
                num_predict=config["ollama"]["max_tokens"],
                timeout=config["ollama"]["timeout"]
            )
            print("âœ… LLM initialized successfully")
        except Exception as e:
            print(f"âŒ Failed to initialize LLM: {e}")
            raise
        
    def load_class_notes(self) -> Dict[str, str]:
        """Load all class notes files"""
        notes = {}
        
        if not self.class_notes_path.exists():
            print(f"âš ï¸  Class notes directory not found: {self.class_notes_path}")
            return notes
            
        for file_path in self.class_notes_path.glob("*.txt"):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    notes[file_path.stem] = content
                    print(f"ğŸ“– Loaded: {file_path.name}")
            except Exception as e:
                print(f"âŒ Error loading {file_path.name}: {e}")
                
        return notes
    
    async def extract_dream_framework(self, notes: Dict[str, str]) -> str:
        """Extract and structure DREAM framework from class notes using LLM"""
        
        # Combine all relevant notes
        all_notes = "\n\n".join([f"=== {filename} ===\n{content}"
                                for filename, content in notes.items()])
        
        prompt_template = PromptTemplate(
            input_variables=["notes"],
            template="""
åŸºäºä»¥ä¸‹è¯¾ç¨‹ç¬”è®°å†…å®¹ï¼Œè¯·ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„DREAMå•†ä¸šåˆ†ææ¡†æ¶è¯¦è§£æ–‡æ¡£ã€‚

è¯¾ç¨‹ç¬”è®°å†…å®¹ï¼š
{notes}

è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„ç”Ÿæˆæ¡†æ¶æ–‡æ¡£ï¼š

# DREAMå•†ä¸šåˆ†ææ¡†æ¶è¯¦è§£

## æ¡†æ¶æ¦‚è¿°
- åŸºäºè¯¾ç¨‹ç¬”è®°æ€»ç»“DREAMæ¡†æ¶çš„æ ¸å¿ƒç†å¿µå’Œä»·å€¼
- è¯´æ˜DREAMäº”ä¸ªç»´åº¦çš„å«ä¹‰å’Œç›¸äº’å…³ç³»

## ç¬¬ä¸€æ­¥ï¼šéœ€æ±‚åˆ†æ (Demand)
- åŸºäºç¬”è®°ä¸­çš„éœ€æ±‚åˆ†æå†…å®¹ï¼Œè¯¦ç»†é˜è¿°éœ€æ±‚åˆ†æçš„æ ¸å¿ƒåŸåˆ™ã€åˆ†æè¦ç´ å’ŒéªŒè¯æ–¹æ³•

## ç¬¬äºŒæ­¥ï¼šè§£å†³æ–¹æ¡ˆåˆ†æ (Resolution)
- åŸºäºsolution.txtå’Œç›¸å…³å†…å®¹ï¼Œè¯¦ç»†è¯´æ˜äº§å“å†…æ ¸å®šä¹‰ã€ä»·å€¼è¯„ä¼°å’ŒéªŒè¯ç­–ç•¥

## ç¬¬ä¸‰æ­¥ï¼šå•†ä¸šæ¨¡å¼åˆ†æ (Earning)
- åŸºäºå•†ä¸šæ¨¡å¼ç›¸å…³å†…å®¹ï¼Œè¯´æ˜å•ä½ç»æµå­¦å»ºæ¨¡ã€ä¸‰å¤§æ ¸å¿ƒèƒ½åŠ›å’Œå¥åº·åº¦è¯„ä¼°æ ‡å‡†

## ç¬¬å››æ­¥ï¼šå¢é•¿åˆ†æ (Acquisition)
- åŸºäºAARRRå’Œå¢é•¿ç›¸å…³å†…å®¹ï¼Œè¯´æ˜è·å®¢ç­–ç•¥å’Œè§„æ¨¡åŒ–æœºåˆ¶

## ç¬¬äº”æ­¥ï¼šå£å’åˆ†æ (Moat)
- åŸºäºç«äº‰ä¼˜åŠ¿ç›¸å…³å†…å®¹ï¼Œè¯´æ˜æŠ¤åŸæ²³æ„å»ºç­–ç•¥

## å‡è®¾é©±åŠ¨æ–¹æ³•è®º
- åŸºäºassumption_driven.txtå†…å®¹ï¼Œè¯¦ç»†è¯´æ˜å…³é”®å‡è®¾ä¸‰æ­¥æ³•å’ŒéªŒè¯æ–¹æ³•åˆ†ç±»

## åº”ç”¨åŸåˆ™
- æ€»ç»“æ¡†æ¶åº”ç”¨çš„æ ¸å¿ƒåŸåˆ™å’Œæ³¨æ„äº‹é¡¹

è¯·ç¡®ä¿ï¼š
1. å†…å®¹å®Œå…¨åŸºäºæä¾›çš„è¯¾ç¨‹ç¬”è®°
2. ä¿æŒä¸­æ–‡è¡¨è¾¾çš„ä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§
3. ç»“æ„æ¸…æ™°ï¼Œé€»è¾‘è¿è´¯
4. åŒ…å«å…·ä½“çš„æ–¹æ³•å’Œå·¥å…·
5. åœ¨æ–‡æ¡£æœ«å°¾æ·»åŠ æ›´æ–°æ—¶é—´

ç”Ÿæˆçš„å†…å®¹åº”è¯¥æ˜¯ä¸€ä¸ªå®Œæ•´çš„Markdownæ–‡æ¡£ã€‚
"""
        )
        
        formatted_prompt = prompt_template.format(notes=all_notes)
        result = self.llm.invoke(formatted_prompt)
        
        return result
    
    async def extract_hypothesis_methodology(self, notes: Dict[str, str]) -> str:
        """Extract hypothesis-driven methodology from class notes using LLM"""
        
        # Focus on assumption-driven and key assumption breakdown notes
        relevant_notes = {
            'assumption_driven': notes.get('assumption_driven', ''),
            'key_assumption_break_down': notes.get('key_assumption_break_down', ''),
            'business_course_notes_summary': notes.get('business_course_notes_summary', '')
        }
        
        combined_notes = "\n\n".join([f"=== {filename} ===\n{content}"
                                     for filename, content in relevant_notes.items() if content])
        
        prompt_template = PromptTemplate(
            input_variables=["notes"],
            template="""
åŸºäºä»¥ä¸‹è¯¾ç¨‹ç¬”è®°å†…å®¹ï¼Œè¯·ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„å‡è®¾é©±åŠ¨å•†ä¸šåˆ†ææ–¹æ³•è®ºæ–‡æ¡£ã€‚

ç›¸å…³ç¬”è®°å†…å®¹ï¼š
{notes}

è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„ç”Ÿæˆæ–¹æ³•è®ºæ–‡æ¡£ï¼š

# å‡è®¾é©±åŠ¨å•†ä¸šåˆ†ææ–¹æ³•è®º

## æ–¹æ³•è®ºæ¦‚è¿°
- åŸºäºç¬”è®°å†…å®¹é˜è¿°å‡è®¾é©±åŠ¨åˆ†æçš„æ ¸å¿ƒç†å¿µå’Œä»·å€¼

## å‡è®¾è¯†åˆ«ä¸‰æ­¥æ³•
### ç¬¬ä¸€æ­¥ï¼šåŠ æ³•ç¯èŠ‚ - å‡è®¾æ‹†è§£
- åŸºäºå•†ä¸šç”»å¸ƒä¹è¦ç´ è¿›è¡Œå‡è®¾æ‹†è§£
- è¯´æ˜ä»·å€¼å‡è®¾å’Œå¢é•¿å‡è®¾çš„åˆ†ç±»

### ç¬¬äºŒæ­¥ï¼šå‡æ³•ç¯èŠ‚ - å…³é”®å‡è®¾ç­›é€‰
- åŸºäºå…³é”®å‡è®¾ABCDæ¨¡å‹è¿›è¡Œç­›é€‰
- è¯´æ˜ä¼˜å…ˆçº§è¯„ä¼°æ ‡å‡†

### ç¬¬ä¸‰æ­¥ï¼šéªŒè¯ç¯èŠ‚ - å¿«é€Ÿå­¦ä¹ éªŒè¯
- è¯¦ç»†è¯´æ˜ä¸‰ç§éªŒè¯æ–¹æ³•ï¼šé å¸¸è¯†ã€é è°ƒç ”ã€é å®éªŒ

## ä¸šåŠ¡æ‹†è§£ä¸å‡è®¾ç®¡ç†
- åŸºäºä¸šåŠ¡å…¬å¼ABCæ¨¡å‹
- è¯¦ç»†è¯´æ˜åå¤§ä¸šåŠ¡æ‹†è§£èŒƒå¼
- å‡è®¾ç®¡ç†äº”ç¯èŠ‚æµç¨‹

## è½¬åŒ–ç‡ä¼˜åŒ–æ–¹æ³•
- åŸºäºç¬”è®°ä¸­çš„è½¬åŒ–ç‡hill climbingå†…å®¹

è¯·ç¡®ä¿ï¼š
1. å®Œå…¨åŸºäºæä¾›çš„è¯¾ç¨‹ç¬”è®°å†…å®¹
2. ä¿æŒä¸“ä¸šæ€§å’Œå®ç”¨æ€§
3. ç»“æ„æ¸…æ™°ï¼Œä¾¿äºç†è§£å’Œåº”ç”¨
4. åŒ…å«å…·ä½“çš„æ–¹æ³•å’Œå·¥å…·
5. åœ¨æ–‡æ¡£æœ«å°¾æ·»åŠ æ›´æ–°æ—¶é—´

ç”Ÿæˆçš„å†…å®¹åº”è¯¥æ˜¯ä¸€ä¸ªå®Œæ•´çš„Markdownæ–‡æ¡£ã€‚
"""
        )
        
        formatted_prompt = prompt_template.format(notes=combined_notes)
        result = self.llm.invoke(formatted_prompt)
        
        return result
    
    async def extract_scientific_decision_framework(self, notes: Dict[str, str]) -> str:
        """Extract scientific decision-making framework using LLM"""
        
        scientific_decision = notes.get('scientific_decision', '')
        business_summary = notes.get('business_course_notes_summary', '')
        
        combined_notes = f"""=== scientific_decision ===
{scientific_decision}

=== business_course_notes_summary ===
{business_summary}"""
        
        prompt_template = PromptTemplate(
            input_variables=["notes"],
            template="""
åŸºäºä»¥ä¸‹è¯¾ç¨‹ç¬”è®°å†…å®¹ï¼Œè¯·ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„ç§‘å­¦å†³ç­–æ¡†æ¶æ–‡æ¡£ã€‚

ç›¸å…³ç¬”è®°å†…å®¹ï¼š
{notes}

è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„ç”Ÿæˆç§‘å­¦å†³ç­–æ¡†æ¶æ–‡æ¡£ï¼š

# ç§‘å­¦å†³ç­–æ¡†æ¶

## å†³ç­–è¯„ä¼°ä¹ æƒ¯å±‚æ¬¡
- åŸºäºç¬”è®°ä¸­çš„å†³ç­–æˆç†Ÿåº¦äº”ä¸ªå±‚æ¬¡è¿›è¡Œè¯¦ç»†è¯´æ˜

## ç§‘å­¦å†³ç­–ä¸‰ç»´æ¡†æ¶
### 1. å®½åº¦ (Breadth) - å…¨é¢è€ƒè™‘
- å…³é”®æ”¶ç›Šé¡¹åˆ†æ
- å…³é”®æˆæœ¬é¡¹åˆ†æ

### 2. æ·±åº¦ (Depth) - åˆ†æå±‚æ¬¡
- ä»å®šæ€§åˆ°å®šé‡çš„æ¸è¿›å¼åˆ†ææ·±åŒ–
- åˆ†æå±‚æ¬¡é€’è¿›

### 3. é«˜åº¦ (Height) - æˆ˜ç•¥è§†è§’
- å››ä¸ªæˆ˜ç•¥ç»´åº¦çš„è¯¦ç»†è¯´æ˜

## ç¨€ç¼ºæœºä¼šçª—å£åˆ†æ
- åŸºäºç¬”è®°ä¸­çš„äº”ç±»å…³é”®çª—å£æœŸè¿›è¡Œè¯¦ç»†è¯´æ˜

## å†³ç­–è¯„ä¼°ä¸‰ç»´åº¦
- åŸºäºç¬”è®°ä¸­çš„æ ¸å¿ƒå†³ç­–é—®é¢˜å’Œä¸‰ä¸ªå…³é”®ç»´åº¦

è¯·ç¡®ä¿ï¼š
1. å®Œå…¨åŸºäºæä¾›çš„è¯¾ç¨‹ç¬”è®°å†…å®¹
2. ä¿æŒä¸“ä¸šæ€§å’Œå®ç”¨æ€§
3. ç»“æ„æ¸…æ™°ï¼Œä¾¿äºç†è§£å’Œåº”ç”¨
4. åŒ…å«å…·ä½“çš„å†³ç­–å·¥å…·å’Œæ–¹æ³•
5. åœ¨æ–‡æ¡£æœ«å°¾æ·»åŠ æ›´æ–°æ—¶é—´

ç”Ÿæˆçš„å†…å®¹åº”è¯¥æ˜¯ä¸€ä¸ªå®Œæ•´çš„Markdownæ–‡æ¡£ã€‚
"""
        )
        
        formatted_prompt = prompt_template.format(notes=combined_notes)
        result = self.llm.invoke(formatted_prompt)
        
        return result
    
    async def generate_unit_economics_template(self, notes: Dict[str, str]) -> str:
        """Generate enhanced unit economics template using LLM"""
        
        business_summary = notes.get('business_course_notes_summary', '')
        earning_related = notes.get('assumption_driven', '')
        
        combined_notes = f"""=== business_course_notes_summary ===
{business_summary}

=== assumption_driven ===
{earning_related}"""
        
        prompt_template = PromptTemplate(
            input_variables=["notes"],
            template="""
åŸºäºä»¥ä¸‹è¯¾ç¨‹ç¬”è®°å†…å®¹ï¼Œè¯·ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„å•ä½ç»æµå­¦å»ºæ¨¡æŒ‡å—æ–‡æ¡£ã€‚

ç›¸å…³ç¬”è®°å†…å®¹ï¼š
{notes}

è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„ç”Ÿæˆå•ä½ç»æµå­¦æŒ‡å—ï¼š

# å•ä½ç»æµå­¦å»ºæ¨¡å®Œæ•´æŒ‡å—

## æ¦‚è¿°
- åŸºäºç¬”è®°å†…å®¹è¯´æ˜å•ä½ç»æµå­¦çš„é‡è¦æ€§å’Œåº”ç”¨ä»·å€¼

## å•ä½æ¨¡å‹å®šä¹‰
- åŸºäºç¬”è®°ä¸­å…³äºå•ä½æ¨¡å‹çš„å†…å®¹ï¼Œè¯´æ˜ä»€ä¹ˆæ˜¯å•ä½æ¨¡å‹
- å•ä½é€‰æ‹©æ ‡å‡†å’Œå¸¸è§å•ä½ç±»å‹

## æ”¶å…¥æ¨¡å‹è®¾è®¡
- åŸºäºå•†ä¸šæ¨¡å¼ç›¸å…³å†…å®¹ï¼Œè¯¦ç»†è¯´æ˜å„ç§æ”¶å…¥æ¨¡å¼åˆ†ç±»
- æ¯ç§æ¨¡å¼çš„é€‚ç”¨åœºæ™¯å’Œç‰¹ç‚¹

## æˆæœ¬ç»“æ„åˆ†æ
- åŸºäºç¬”è®°ä¸­çš„æˆæœ¬åˆ†æå†…å®¹ï¼Œè¯´æ˜æˆæœ¬åˆ†ç±»æ–¹æ³•
- å›ºå®šæˆæœ¬ã€å˜åŠ¨æˆæœ¬ã€åŠå˜åŠ¨æˆæœ¬çš„ç‰¹ç‚¹

## å…³é”®æŒ‡æ ‡ä½“ç³»
- åŸºäºç¬”è®°ä¸­çš„æ ¸å¿ƒæŒ‡æ ‡å†…å®¹ï¼Œè¯¦ç»†è¯´æ˜ï¼š
  - æ ¸å¿ƒè´¢åŠ¡æŒ‡æ ‡ï¼ˆå•ä½æ”¶å…¥ã€æˆæœ¬ã€è´¡çŒ®è¾¹é™…ç­‰ï¼‰
  - ç”¨æˆ·ç”Ÿå‘½å‘¨æœŸæŒ‡æ ‡ï¼ˆCACã€LTVã€å›æ”¶æœŸç­‰ï¼‰

## å¥åº·åº¦è¯„ä¼°æ ‡å‡†
- åŸºäºè¡Œä¸šç»éªŒå’Œç¬”è®°å†…å®¹ï¼Œæä¾›å¥åº·åº¦è¯„ä¼°æ ‡å‡†

## ä¼˜åŒ–ç­–ç•¥æ¡†æ¶
- åŸºäºç¬”è®°å†…å®¹ï¼Œæä¾›æ”¶å…¥ä¼˜åŒ–ã€æˆæœ¬ä¼˜åŒ–ã€è·å®¢æ•ˆç‡ä¼˜åŒ–ç­–ç•¥

è¯·ç¡®ä¿ï¼š
1. å®Œå…¨åŸºäºæä¾›çš„è¯¾ç¨‹ç¬”è®°å†…å®¹
2. ä¿æŒä¸“ä¸šæ€§å’Œå®ç”¨æ€§
3. ç»“æ„æ¸…æ™°ï¼Œä¾¿äºç†è§£å’Œåº”ç”¨
4. åŒ…å«å…·ä½“çš„è®¡ç®—å…¬å¼å’Œè¯„ä¼°æ ‡å‡†
5. åœ¨æ–‡æ¡£æœ«å°¾æ·»åŠ æ›´æ–°æ—¶é—´

ç”Ÿæˆçš„å†…å®¹åº”è¯¥æ˜¯ä¸€ä¸ªå®Œæ•´çš„Markdownæ–‡æ¡£ã€‚
"""
        )
        
        formatted_prompt = prompt_template.format(notes=combined_notes)
        result = self.llm.invoke(formatted_prompt)
        
        return result

class KnowledgeBaseUpdater:
    """Update knowledge base from class notes"""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.class_notes_path = project_root.parent / "class_notes"
        self.data_path = project_root / "data"
        self.config_path = project_root / "config" / "ollama_config.yaml"
        self.generator = LLMContentGenerator(self.class_notes_path, self.config_path)
        
    async def update_knowledge_base(self):
        """Main function to update knowledge base"""
        print("ğŸ”„ Updating DREAM Business Analysis Knowledge Base from Class Notes")
        print("=" * 70)
        
        # Load class notes
        print("\nğŸ“š Loading class notes...")
        notes = self.generator.load_class_notes()
        
        if not notes:
            print("âŒ No class notes found. Please check the class_notes directory.")
            return False
            
        print(f"âœ… Loaded {len(notes)} class note files")
        
        # Create directories
        self._ensure_directories()
        
        # Generate content from class notes
        print("\nğŸ”„ Generating knowledge base content...")
        
        # Update frameworks
        await self._update_frameworks(notes)
        
        # Update templates
        await self._update_templates(notes)
        
        # Update case studies
        await self._update_case_studies(notes)
        
        # Update benchmarks
        await self._update_benchmarks(notes)
        
        # Rebuild vector database
        print("\nğŸ”„ Rebuilding vector database...")
        success = await self._rebuild_vector_database()
        
        if success:
            print("\nğŸ‰ Knowledge base update completed successfully!")
            print("\nğŸ“Š Updated content:")
            self._show_update_summary()
            return True
        else:
            print("\nâŒ Vector database rebuild failed")
            return False
    
    def _ensure_directories(self):
        """Ensure all required directories exist"""
        directories = ["frameworks", "templates", "case_studies", "benchmarks"]
        for directory in directories:
            (self.data_path / directory).mkdir(parents=True, exist_ok=True)
    
    async def _update_frameworks(self, notes: Dict[str, str]):
        """Update framework files"""
        print("  ğŸ“‹ Updating frameworks...")
        
        # DREAM Framework
        dream_content = await self.generator.extract_dream_framework(notes)
        dream_path = self.data_path / "frameworks" / "dream_framework_detailed.md"
        with open(dream_path, 'w', encoding='utf-8') as f:
            f.write(dream_content)
        print(f"    âœ… Updated: {dream_path.name}")
        
        # Hypothesis Methodology
        hypothesis_content = await self.generator.extract_hypothesis_methodology(notes)
        hypothesis_path = self.data_path / "frameworks" / "hypothesis_driven_methodology.md"
        with open(hypothesis_path, 'w', encoding='utf-8') as f:
            f.write(hypothesis_content)
        print(f"    âœ… Updated: {hypothesis_path.name}")
        
        # Scientific Decision Framework
        decision_content = await self.generator.extract_scientific_decision_framework(notes)
        decision_path = self.data_path / "frameworks" / "scientific_decision_framework.md"
        with open(decision_path, 'w', encoding='utf-8') as f:
            f.write(decision_content)
        print(f"    âœ… Created: {decision_path.name}")
    
    async def _update_templates(self, notes: Dict[str, str]):
        """Update template files"""
        print("  ğŸ“ Updating templates...")
        
        # Unit Economics Template
        unit_economics_content = await self.generator.generate_unit_economics_template(notes)
        unit_economics_path = self.data_path / "templates" / "unit_economics_modeling.md"
        with open(unit_economics_path, 'w', encoding='utf-8') as f:
            f.write(unit_economics_content)
        print(f"    âœ… Updated: {unit_economics_path.name}")
        
        # Business Canvas Template
        canvas_content = await self._generate_business_canvas_template(notes)
        canvas_path = self.data_path / "templates" / "business_canvas_template.md"
        with open(canvas_path, 'w', encoding='utf-8') as f:
            f.write(canvas_content)
        print(f"    âœ… Created: {canvas_path.name}")
        
        # Hypothesis Testing Template
        hypothesis_template = await self._generate_hypothesis_testing_template(notes)
        hypothesis_path = self.data_path / "templates" / "hypothesis_testing_template.md"
        with open(hypothesis_path, 'w', encoding='utf-8') as f:
            f.write(hypothesis_template)
        print(f"    âœ… Created: {hypothesis_path.name}")
    
    async def _update_case_studies(self, notes: Dict[str, str]):
        """Update case study files"""
        print("  ğŸ“– Updating case studies...")
        
        # Generate example case studies based on frameworks
        case_study = await self._generate_example_case_study(notes)
        case_path = self.data_path / "case_studies" / "saas_platform_analysis.json"
        with open(case_path, 'w', encoding='utf-8') as f:
            json.dump(case_study, f, ensure_ascii=False, indent=2)
        print(f"    âœ… Created: {case_path.name}")
    
    async def _update_benchmarks(self, notes: Dict[str, str]):
        """Update benchmark files"""
        print("  ğŸ“Š Updating benchmarks...")
        
        # Industry benchmarks
        benchmarks = await self._generate_industry_benchmarks(notes)
        benchmark_path = self.data_path / "benchmarks" / "industry_benchmarks.md"
        with open(benchmark_path, 'w', encoding='utf-8') as f:
            f.write(benchmarks)
        print(f"    âœ… Created: {benchmark_path.name}")
    
    async def _generate_business_canvas_template(self, notes: Dict[str, str]) -> str:
        """Generate business canvas template using LLM"""
        
        relevant_notes = {
            'assumption_driven': notes.get('assumption_driven', ''),
            'business_course_notes_summary': notes.get('business_course_notes_summary', ''),
            'key_assumption_break_down': notes.get('key_assumption_break_down', '')
        }
        
        combined_notes = "\n\n".join([f"=== {filename} ===\n{content}"
                                     for filename, content in relevant_notes.items() if content])
        
        prompt_template = PromptTemplate(
            input_variables=["notes"],
            template="""
åŸºäºä»¥ä¸‹è¯¾ç¨‹ç¬”è®°å†…å®¹ï¼Œè¯·ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„å•†ä¸šç”»å¸ƒåˆ†ææ¨¡æ¿ã€‚

ç›¸å…³ç¬”è®°å†…å®¹ï¼š
{notes}

è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„ç”Ÿæˆå•†ä¸šç”»å¸ƒæ¨¡æ¿ï¼š

# å•†ä¸šç”»å¸ƒåˆ†ææ¨¡æ¿

## å•†ä¸šç”»å¸ƒä¹è¦ç´ 
åŸºäºDREAMæ¡†æ¶å’Œå‡è®¾é©±åŠ¨æ–¹æ³•è®ºï¼Œè¯¦ç»†è¯´æ˜å•†ä¸šç”»å¸ƒçš„ä¹ä¸ªæ ¸å¿ƒè¦ç´ ï¼š

### 1. éœ€æ±‚åˆ†æ
- åŸºäºç¬”è®°ä¸­çš„éœ€æ±‚åˆ†æå†…å®¹ï¼Œè®¾è®¡ç»†åˆ†ç”¨æˆ·ã€éœ€æ±‚ã€æ ¸å¿ƒå–ç‚¹çš„åˆ†ææ¡†æ¶

### 2. è§£å†³æ–¹æ¡ˆ
- åŸºäºsolution.txtå†…å®¹ï¼Œè®¾è®¡äº§å“å†…æ ¸å’Œè§£å†³æ–¹æ¡ˆåˆ†ææ¡†æ¶

### 3. å•†ä¸šæ¨¡å¼
- åŸºäºå•†ä¸šæ¨¡å¼ç›¸å…³å†…å®¹ï¼Œè®¾è®¡æ”¶å…¥ã€æˆæœ¬ã€æ ¸å¿ƒæŒ‡æ ‡çš„åˆ†ææ¡†æ¶

### 4. è·å®¢æ¸ é“
- åŸºäºAARRRå’Œè·å®¢ç›¸å…³å†…å®¹ï¼Œè®¾è®¡è·å®¢æ¸ é“åˆ†ææ¡†æ¶

### 5. å£å’
- åŸºäºç«äº‰ä¼˜åŠ¿ç›¸å…³å†…å®¹ï¼Œè®¾è®¡å£å’åˆ†ææ¡†æ¶

## å…³é”®å‡è®¾è¯†åˆ«
- åŸºäºå‡è®¾é©±åŠ¨æ–¹æ³•è®ºï¼Œè®¾è®¡ä»·å€¼å‡è®¾å’Œå¢é•¿å‡è®¾çš„è¯†åˆ«æ¡†æ¶

## éªŒè¯è®¡åˆ’
- åŸºäºä¸‰ç§éªŒè¯æ–¹æ³•ï¼ˆå¸¸è¯†ã€è°ƒç ”ã€å®éªŒï¼‰ï¼Œè®¾è®¡éªŒè¯è®¡åˆ’æ¨¡æ¿

è¯·ç¡®ä¿ï¼š
1. å®Œå…¨åŸºäºæä¾›çš„è¯¾ç¨‹ç¬”è®°å†…å®¹
2. ä¿æŒæ¨¡æ¿çš„å®ç”¨æ€§å’Œå¯æ“ä½œæ€§
3. ç»“æ„æ¸…æ™°ï¼Œä¾¿äºå¡«å†™å’Œä½¿ç”¨
4. åŒ…å«å…·ä½“çš„åˆ†æè¦ç‚¹å’ŒæŒ‡å¯¼
5. åœ¨æ–‡æ¡£æœ«å°¾æ·»åŠ æ›´æ–°æ—¶é—´

ç”Ÿæˆçš„å†…å®¹åº”è¯¥æ˜¯ä¸€ä¸ªå®Œæ•´çš„Markdownæ¨¡æ¿æ–‡æ¡£ã€‚
"""
        )
        
        formatted_prompt = prompt_template.format(notes=combined_notes)
        result = self.generator.llm.invoke(formatted_prompt)
        
        return result
    
    async def _generate_hypothesis_testing_template(self, notes: Dict[str, str]) -> str:
        """Generate hypothesis testing template using LLM"""
        
        relevant_notes = {
            'assumption_driven': notes.get('assumption_driven', ''),
            'key_assumption_break_down': notes.get('key_assumption_break_down', ''),
            'scientific_decision': notes.get('scientific_decision', '')
        }
        
        combined_notes = "\n\n".join([f"=== {filename} ===\n{content}"
                                     for filename, content in relevant_notes.items() if content])
        
        prompt_template = PromptTemplate(
            input_variables=["notes"],
            template="""
åŸºäºä»¥ä¸‹è¯¾ç¨‹ç¬”è®°å†…å®¹ï¼Œè¯·ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„å‡è®¾æµ‹è¯•æ¨¡æ¿ã€‚

ç›¸å…³ç¬”è®°å†…å®¹ï¼š
{notes}

è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„ç”Ÿæˆå‡è®¾æµ‹è¯•æ¨¡æ¿ï¼š

# å‡è®¾æµ‹è¯•æ¨¡æ¿

## å‡è®¾åŸºæœ¬ä¿¡æ¯
- è®¾è®¡å‡è®¾çš„åŸºæœ¬ä¿¡æ¯è®°å½•æ¡†æ¶

## å‡è®¾æè¿°
- åŸºäºç¬”è®°å†…å®¹ï¼Œè®¾è®¡å‡è®¾é™ˆè¿°å’ŒèƒŒæ™¯æè¿°æ¡†æ¶

## ä¼˜å…ˆçº§è¯„ä¼°
- åŸºäºå…³é”®å‡è®¾ABCDæ¨¡å‹å’Œç§‘å­¦å†³ç­–æ¡†æ¶ï¼Œè®¾è®¡ä¼˜å…ˆçº§è¯„ä¼°æ¡†æ¶
- åŒ…å«å½±å“è¯„ä¼°ã€å¯è¡Œæ€§è¯„ä¼°ã€æ—¶é—´çª—å£ç­‰ç»´åº¦

## éªŒè¯æ–¹æ¡ˆè®¾è®¡
- åŸºäºä¸‰ç§éªŒè¯æ–¹æ³•ï¼ˆå¸¸è¯†ã€è°ƒç ”ã€å®éªŒï¼‰ï¼Œè®¾è®¡éªŒè¯æ–¹æ¡ˆæ¡†æ¶
- åŒ…å«éªŒè¯ç›®æ ‡ã€æ–¹æ³•ã€èµ„æºéœ€æ±‚ç­‰

## éªŒè¯æ‰§è¡Œ
- è®¾è®¡æ‰§è¡Œè®¡åˆ’å’Œé£é™©æ§åˆ¶æ¡†æ¶

## éªŒè¯ç»“æœ
- è®¾è®¡ç»“æœæ”¶é›†ã€åˆ†æå’Œç»“è®ºæ¡†æ¶

## å­¦ä¹ æ€»ç»“
- è®¾è®¡ç»éªŒæ•™è®­å’ŒçŸ¥è¯†æ²‰æ·€æ¡†æ¶

è¯·ç¡®ä¿ï¼š
1. å®Œå…¨åŸºäºæä¾›çš„è¯¾ç¨‹ç¬”è®°å†…å®¹
2. ä¿æŒæ¨¡æ¿çš„å®ç”¨æ€§å’Œå¯æ“ä½œæ€§
3. ç»“æ„æ¸…æ™°ï¼Œä¾¿äºå¡«å†™å’Œä½¿ç”¨
4. åŒ…å«å…·ä½“çš„è¯„ä¼°æ ‡å‡†å’ŒæŒ‡å¯¼
5. åœ¨æ–‡æ¡£æœ«å°¾æ·»åŠ æ›´æ–°æ—¶é—´

ç”Ÿæˆçš„å†…å®¹åº”è¯¥æ˜¯ä¸€ä¸ªå®Œæ•´çš„Markdownæ¨¡æ¿æ–‡æ¡£ã€‚
"""
        )
        
        formatted_prompt = prompt_template.format(notes=combined_notes)
        result = self.generator.llm.invoke(formatted_prompt)
        
        return result
    
    async def _generate_example_case_study(self, notes: Dict[str, str]) -> Dict[str, Any]:
        """Generate example case study using LLM"""
        
        all_notes = "\n\n".join([f"=== {filename} ===\n{content}"
                                for filename, content in notes.items()])
        
        prompt_template = PromptTemplate(
            input_variables=["notes"],
            template="""
åŸºäºä»¥ä¸‹è¯¾ç¨‹ç¬”è®°å†…å®¹ï¼Œè¯·ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„å•†ä¸šåˆ†ææ¡ˆä¾‹ç ”ç©¶ï¼Œä»¥JSONæ ¼å¼è¾“å‡ºã€‚

è¯¾ç¨‹ç¬”è®°å†…å®¹ï¼š
{notes}

è¯·æŒ‰ç…§ä»¥ä¸‹JSONç»“æ„ç”Ÿæˆæ¡ˆä¾‹ç ”ç©¶ï¼š

{{
  "case_id": "æ¡ˆä¾‹å”¯ä¸€æ ‡è¯†",
  "title": "æ¡ˆä¾‹æ ‡é¢˜",
  "industry": "è¡Œä¸šåˆ†ç±»",
  "business_model": "å•†ä¸šæ¨¡å¼ç±»å‹",
  "analysis_date": "åˆ†ææ—¥æœŸ",
  "dream_analysis": {{
    "demand": {{
      "target_users": "ç›®æ ‡ç”¨æˆ·ç¾¤ä½“",
      "use_cases": ["ä½¿ç”¨åœºæ™¯1", "ä½¿ç”¨åœºæ™¯2"],
      "market_size": {{
        "tam": "æ€»ä½“å¯è·å¾—å¸‚åœº",
        "sam": "å¯æœåŠ¡å¸‚åœº",
        "som": "å¯è·å¾—ä»½é¢"
      }},
      "pain_points": ["ç—›ç‚¹1", "ç—›ç‚¹2"]
    }},
    "resolution": {{
      "product_core": "äº§å“å†…æ ¸å®šä¹‰",
      "value_proposition": "ä»·å€¼ä¸»å¼ ",
      "mvp_features": ["æ ¸å¿ƒåŠŸèƒ½1", "æ ¸å¿ƒåŠŸèƒ½2"],
      "user_value_formula": "ç”¨æˆ·ä»·å€¼è®¡ç®—å…¬å¼"
    }},
    "earning": {{
      "revenue_model": "æ”¶å…¥æ¨¡å¼",
      "pricing": "å®šä»·ç­–ç•¥",
      "unit_economics": {{
        "arpu": "å¹³å‡ç”¨æˆ·æ”¶å…¥",
        "cac": "å®¢æˆ·è·å–æˆæœ¬",
        "ltv": "å®¢æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼",
        "ltv_cac_ratio": "LTV/CACæ¯”ç‡",
        "payback_period": "å›æ”¶æœŸ"
      }},
      "cost_structure": {{
        "fixed_costs": ["å›ºå®šæˆæœ¬é¡¹"],
        "variable_costs": ["å˜åŠ¨æˆæœ¬é¡¹"]
      }}
    }},
    "acquisition": {{
      "channels": ["è·å®¢æ¸ é“"],
      "aarrr": {{
        "acquisition": "è·å®¢æ•°æ®",
        "activation": "æ¿€æ´»ç‡",
        "retention": "ç•™å­˜ç‡",
        "revenue": "æ”¶å…¥è½¬åŒ–",
        "referral": "æ¨èç‡"
      }}
    }},
    "moat": {{
      "competitive_advantages": ["ç«äº‰ä¼˜åŠ¿"],
      "barriers": ["è¿›å…¥å£å’"],
      "sustainability": "å¯æŒç»­æ€§æè¿°"
    }}
  }},
  "key_hypotheses": [
    {{
      "type": "å‡è®¾ç±»å‹",
      "description": "å‡è®¾æè¿°",
      "validation_method": "éªŒè¯æ–¹æ³•",
      "result": "éªŒè¯ç»“æœ"
    }}
  ],
  "lessons_learned": [
    "ç»éªŒæ•™è®­1",
    "ç»éªŒæ•™è®­2"
  ]
}}

è¯·ç¡®ä¿ï¼š
1. å®Œå…¨åŸºäºæä¾›çš„è¯¾ç¨‹ç¬”è®°å†…å®¹
2. æ¡ˆä¾‹å…·æœ‰ç°å®æ€§å’Œå¯ä¿¡åº¦
3. æ•°æ®åˆç†ä¸”ç¬¦åˆè¡Œä¸šå¸¸è¯†
4. ä½“ç°DREAMæ¡†æ¶çš„å®Œæ•´åº”ç”¨
5. åŒ…å«å‡è®¾é©±åŠ¨çš„éªŒè¯è¿‡ç¨‹

åªè¿”å›JSONæ ¼å¼çš„å†…å®¹ï¼Œä¸è¦åŒ…å«å…¶ä»–è¯´æ˜æ–‡å­—ã€‚
"""
        )
        
        formatted_prompt = prompt_template.format(notes=all_notes)
        result = self.generator.llm.invoke(formatted_prompt)
        
        # Parse the JSON result
        try:
            import json
            case_study = json.loads(result)
            return case_study
        except json.JSONDecodeError:
            # Fallback to a basic structure if JSON parsing fails
            return {
                "case_id": "llm_generated_001",
                "title": "LLMç”Ÿæˆçš„å•†ä¸šåˆ†ææ¡ˆä¾‹",
                "industry": "åŸºäºè¯¾ç¨‹ç¬”è®°ç”Ÿæˆ",
                "business_model": "åŠ¨æ€ç”Ÿæˆ",
                "analysis_date": datetime.now().strftime('%Y-%m-%d'),
                "dream_analysis": {"note": "LLMç”Ÿæˆçš„åˆ†æå†…å®¹"},
                "key_hypotheses": [],
                "lessons_learned": ["åŸºäºè¯¾ç¨‹ç¬”è®°çš„LLMåˆ†æ"]
            }
    
    async def _generate_industry_benchmarks(self, notes: Dict[str, str]) -> str:
        """Generate industry benchmarks using LLM"""
        
        business_summary = notes.get('business_course_notes_summary', '')
        assumption_driven = notes.get('assumption_driven', '')
        
        combined_notes = f"""=== business_course_notes_summary ===
{business_summary}

=== assumption_driven ===
{assumption_driven}"""
        
        prompt_template = PromptTemplate(
            input_variables=["notes"],
            template="""
åŸºäºä»¥ä¸‹è¯¾ç¨‹ç¬”è®°å†…å®¹ï¼Œè¯·ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„è¡Œä¸šåŸºå‡†æ•°æ®æ–‡æ¡£ã€‚

ç›¸å…³ç¬”è®°å†…å®¹ï¼š
{notes}

è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„ç”Ÿæˆè¡Œä¸šåŸºå‡†æ•°æ®ï¼š

# è¡Œä¸šåŸºå‡†æ•°æ®

## æ ¸å¿ƒå•†ä¸šæŒ‡æ ‡åŸºå‡†
- åŸºäºç¬”è®°ä¸­çš„å•ä½ç»æµå­¦å’Œå•†ä¸šæ¨¡å¼å†…å®¹ï¼Œæä¾›å…³é”®å•†ä¸šæŒ‡æ ‡çš„è¡Œä¸šåŸºå‡†

## SaaSè¡Œä¸šåŸºå‡†
- åŸºäºç¬”è®°å†…å®¹å’Œè¡Œä¸šå¸¸è¯†ï¼Œæä¾›SaaSè¡Œä¸šçš„å…³é”®æŒ‡æ ‡åŸºå‡†
- åŒ…å«LTV/CACã€ç•™å­˜ç‡ã€è½¬åŒ–ç‡ç­‰æ ¸å¿ƒæŒ‡æ ‡

## ç”µå•†è¡Œä¸šåŸºå‡†
- æä¾›ç”µå•†è¡Œä¸šçš„å…³é”®æŒ‡æ ‡åŸºå‡†
- åŒ…å«å¤è´­ç‡ã€è½¬åŒ–ç‡ã€å®¢å•ä»·ç­‰æŒ‡æ ‡

## å¹³å°ä¸šåŠ¡åŸºå‡†
- æä¾›å¹³å°ä¸šåŠ¡çš„å…³é”®æŒ‡æ ‡åŸºå‡†
- åŒ…å«ç½‘ç»œæ•ˆåº”ã€åŒè¾¹å¸‚åœºã€ç”¨æˆ·æ´»è·ƒåº¦ç­‰æŒ‡æ ‡

## ç§»åŠ¨åº”ç”¨åŸºå‡†
- æä¾›ç§»åŠ¨åº”ç”¨çš„å…³é”®æŒ‡æ ‡åŸºå‡†
- åŒ…å«ä¸‹è½½è½¬åŒ–ã€ç•™å­˜ç‡ã€å˜ç°æŒ‡æ ‡ç­‰

## å…¶ä»–é‡è¦è¡Œä¸šåŸºå‡†
- æ ¹æ®ç¬”è®°å†…å®¹ï¼Œè¡¥å……å…¶ä»–ç›¸å…³è¡Œä¸šçš„åŸºå‡†æ•°æ®

## åŸºå‡†æ•°æ®åº”ç”¨æŒ‡å¯¼
- åŸºäºç¬”è®°ä¸­çš„åŸºå‡†åˆ†ææ–¹æ³•ï¼Œè¯´æ˜å¦‚ä½•æ­£ç¡®ä½¿ç”¨åŸºå‡†æ•°æ®è¿›è¡Œå•†ä¸šåˆ†æ

è¯·ç¡®ä¿ï¼š
1. åŸºäºæä¾›çš„è¯¾ç¨‹ç¬”è®°å†…å®¹å’Œè¡Œä¸šå¸¸è¯†
2. æ•°æ®å…·æœ‰å‚è€ƒä»·å€¼å’Œç°å®æ„ä¹‰
3. ç»“æ„æ¸…æ™°ï¼Œä¾¿äºæŸ¥é˜…å’Œä½¿ç”¨
4. åŒ…å«å…·ä½“çš„æ•°å€¼èŒƒå›´å’Œè¯„ä¼°æ ‡å‡†
5. åœ¨æ–‡æ¡£æœ«å°¾æ·»åŠ æ›´æ–°æ—¶é—´å’Œæ•°æ®æ¥æºè¯´æ˜

ç”Ÿæˆçš„å†…å®¹åº”è¯¥æ˜¯ä¸€ä¸ªå®Œæ•´çš„Markdownæ–‡æ¡£ã€‚
"""
        )
        
        formatted_prompt = prompt_template.format(notes=combined_notes)
        result = self.generator.llm.invoke(formatted_prompt)
        
        return result
    
    async def _rebuild_vector_database(self):
        """Rebuild vector database"""
        try:
            # Try to use the existing rebuild script
            import subprocess
            result = subprocess.run([
                sys.executable, "rebuild_vectordb_only.py"
            ], cwd=self.project_root, capture_output=True, text=True)
            
            if result.returncode == 0:
                print("âœ… Vector database rebuilt successfully")
                return True
            else:
                print(f"âŒ Vector database rebuild failed: {result.stderr}")
                print("ğŸ’¡ You can manually run: python rebuild_vectordb.py")
                return False
                
        except Exception as e:
            print(f"âŒ Error rebuilding vector database: {e}")
            print("ğŸ’¡ You can manually run: python rebuild_vectordb.py")
            return False
    
    def _show_update_summary(self):
        """Show summary of updated content"""
        frameworks_count = len(list((self.data_path / "frameworks").glob("*.md")))
        templates_count = len(list((self.data_path / "templates").glob("*.md")))
        case_studies_count = len(list((self.data_path / "case_studies").glob("*.json")))
        benchmarks_count = len(list((self.data_path / "benchmarks").glob("*.md")))
        
        print(f"   ğŸ“‹ Frameworks: {frameworks_count} files")
        print(f"   ğŸ“ Templates: {templates_count} files")
        print(f"   ğŸ“– Case Studies: {case_studies_count} files")
        print(f"   ğŸ“Š Benchmarks: {benchmarks_count} files")
        print(f"   ğŸ“š Total: {frameworks_count + templates_count + case_studies_count + benchmarks_count} files")

async def main():
    """Main function"""
    project_root = Path(__file__).parent
    updater = KnowledgeBaseUpdater(project_root)
    
    success = await updater.update_knowledge_base()
    
    if success:
        print("\nğŸš€ Next steps:")
        print("   1. Review updated content in data/ directory")
        print("   2. Test the system: python test_system.py")
        print("   3. Start the application: python start_streamlit.py")
    else:
        print("\nâŒ Please fix the errors above and try again")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
